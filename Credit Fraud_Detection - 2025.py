# -*- coding: utf-8 -*-
"""CC Fraud Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zKtgiq4VPn33T7snddDvfMQLPVQ8PAJr
"""

import pandas as pd

import numpy as np

import matplotlib.pyplot as plt

import seaborn as sns

import warnings

warnings.filterwarnings("ignore")

sns.set(style="whitegrid")

df = pd.read_csv("/AIML Dataset.csv")

df.head()

df.info()

df.columns

df.isnull().sum()

df.shape

print(df['isFraud'].value_counts(dropna=False))

print(df['isFlaggedFraud'].value_counts(dropna=False))

round((df['isFraud'].value_counts(dropna=False)[1] / df.shape[0]) * 100,2)

#visualising transacrion types

df['type'].value_counts().plot(kind='bar', title='Transaction Types', color = "skyblue")
plt.xlabel('Transaction Type')
plt.ylabel('Count')
plt.show()

#fraud rate by transaction type

fraud_by_type = df.groupby(['type'])['isFraud'].mean().sort_values(ascending=False)
fraud_by_type.plot(kind="bar", title="Fraud Rate by Transaction Type", color="salmon")
plt.xlabel("Transaction Type")
plt.ylabel("Fraud Rate")
plt.show()

#Amounts stats

df["amount"].describe().astype(int)

sns.histplot(np.log1p(df["amount"]), bins=100, kde=True, color= "green")
plt.title("Transaction Amount Distribution (logscale)")
plt.xlabel("Log(Amount + 1)")
plt.show()

sns.boxplot(data=df[df["amount"] < 50000], x = "isFraud", y = "amount")
plt.title("Amount vs isFraud (filtered under 50K)")
plt.show()
# shows more fraude rates filtered under 50K

df["balanceDiffOrig"] = df["oldbalanceOrg"] - df["newbalanceOrig"]
df["balanceDiffDest"] = df["newbalanceDest"] - df["oldbalanceDest"]

df["balanceDiffOrig"] < 0

(df["balanceDiffOrig"] < 0).sum() #negative values

(df["balanceDiffDest"] < 0).sum()

df.head(2)

frauds_per_step = df[df["isFraud"] == 1]["step"].value_counts().sort_index()
plt.plot(frauds_per_step.index, frauds_per_step.values, label="Frauds per Step")
plt.xlabel("Step (Time)")
plt.ylabel("Number of Fraudulant Transactions")
plt.title("Frauds Over Time")
plt.grid(True)
plt.show()

# drop the step
df.drop(columns="step", inplace=True)

# visualize top customer senders

top_senders = df["nameOrig"].value_counts().head(10)
top_senders

# customers who make the most transactions
top_receivers = df["nameDest"].value_counts().head(10)
top_receivers

fraud_users = df[df["isFraud"] == 1]["nameOrig"].value_counts().head(10)
fraud_users

# tranfers and cash outs

fraud_types = df[df["type"].isin(["TRANSFER", "CASH_OUT"])]
fraud_types["type"].value_counts()

sns.countplot(data=fraud_types, x="type", hue="isFraud")
plt.title("Fraud Distribution in Transfer & Cash_Out")
plt.show()

# correlation Matrix

corr = df[["amount", "oldbalanceOrg","newbalanceOrig", "oldbalanceDest", "newbalanceDest", "isFraud"]].corr()

sns.heatmap(corr, annot=True, cmap= "coolwarm", fmt= ".2f")
plt.title("Correlation Matrix")
plt.show()

# balance trasfer

zero_after_transfer = df[
    (df["oldbalanceOrg"] > 0) &
    (df["newbalanceOrig"] == 0) &
    (df["type"].isin(["TRANSFER", "CASH_OUT"]))
]

len(zero_after_transfer)

zero_after_transfer.head()

df["isFraud"].value_counts()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder

#drop columns

df_model = df.drop(["nameOrig", "nameDest", "isFlaggedFraud"], axis = 1)

# Define the columns - set cat and numerical type

categorical = ["type"]
numeric = ["amount", "oldbalanceOrg", "newbalanceOrig", "oldbalanceDest", "newbalanceDest"]

y = df_model["isFraud"]
x = df_model.drop("isFraud", axis = 1)

# Train, test, spli dataset

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, stratify=y)

#preprocessing

preprocessing = ColumnTransformer(
    transformers=[
        ("num", StandardScaler(), numeric),
        ("cat", OneHotEncoder(drop="first"), categorical)
    ],
    remainder= "drop"
)

df.head()

#create model pipelind

pipeline = Pipeline([
    ("prep", preprocessing),
    ("clf", LogisticRegression(class_weight="balanced", max_iter=1000))
])

pipeline.fit(X_train, y_train)

y_pred = pipeline.predict(X_test)

print(classification_report(y_test, y_pred))

#model is good at catching fraud. Precision not that good.

print(confusion_matrix(y_test, y_pred))

pipeline.score(X_test, y_test) * 100

# exporting pipeline

import joblib

joblib.dump(pipeline, "fraud_detection_pipleine.pkl")